<?xml version="1.0" encoding="UTF-8"?>
<beans:beans xmlns="http://www.springframework.org/schema/hadoop"
	xmlns:beans="http://www.springframework.org/schema/beans"
	xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
	xmlns:context="http://www.springframework.org/schema/context"
	xsi:schemaLocation="http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd
		http://www.springframework.org/schema/hadoop https://www.springframework.org/schema/hadoop/spring-hadoop.xsd
		http://www.springframework.org/schema/context https://www.springframework.org/schema/context/spring-context.xsd">

	<context:property-placeholder location="hadoop.properties"/>

	<configuration>
		fs.defaultFS=${hd.fs}
		yarn.resourcemanager.address=${hd.rm}
		mapreduce.framework.name=yarn
		mapreduce.jobhistory.address=${hd.jh}
	</configuration>

	<pig-factory properties-location="pig-server.properties"/>
	
	<script id="hdfsScript" language="groovy" location="copy-files.groovy">
		<property name="localSourceFile" value="${localSourceFile}"/>
		<property name="inputDir" value="${inputDir}"/>
		<property name="outputDir" value="${outputDir}"/>
	</script>	
	
	<pig-runner id="pigRunner"
				pre-action="hdfsScript"
				run-at-startup="true" >
		<script location="password-analysis.pig">
				<arguments>
					inputDir=${inputDir}
					outputDir=${outputDir}		
				</arguments>
		</script>					
	</pig-runner>

</beans:beans>
